{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import tqdm\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "no_epochs = 250\n",
    "batch_size = 64\n",
    "learning_rate = 0.004"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#transform the data and load it into the training and test dataset. \n",
    "training_transform = transforms.Compose(\n",
    "            [\n",
    "            transforms.RandomCrop(padding=4, size=32),\n",
    "\t\t\ttransforms.RandomHorizontalFlip(),\n",
    "\t\t\ttransforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010])     \n",
    "        ])\n",
    "validation_transform = transforms.Compose(\n",
    "            [\n",
    "\t\t\ttransforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010])     \n",
    "        ])\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./../datas/cifar10', \n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=training_transform,\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./../datas/cifar10',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=validation_transform,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train: (40000, 32, 32, 3)\n",
      "Shape of x_test: (10000, 32, 32, 3)\n",
      "Shape of y_train: (40000,)\n",
      "Shape of y_test: (10000,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Extract data and labels\n",
    "cifar10_features = train_dataset.data  # This is already in shape (N, 32, 32, 3)\n",
    "cifar10_labels = np.array(train_dataset.targets)  # Targets are in a list, convert to numpy array\n",
    "\n",
    "# Split the CIFAR-10 data into train and test sets using sklearn's train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    cifar10_features, cifar10_labels, test_size=0.2, shuffle=True, random_state=42\n",
    ")\n",
    "\n",
    "# Convert to float64 if necessary (PyTorch expects float32, so double-check your needs)\n",
    "x_train = x_train.astype('float64')\n",
    "x_test = x_test.astype('float64')\n",
    "\n",
    "# Check the shapes of the train and test sets\n",
    "print(\"Shape of x_train:\", x_train.shape)\n",
    "print(\"Shape of x_test:\", x_test.shape)\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "print(\"Shape of y_test:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=True\n",
    "                            )\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                    batch_size=batch_size,\n",
    "                                    shuffle=False\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the training function. Train, show the loss and accuracy for every epoch.\n",
    "def train_model_function(model, train_loader, criterion, optimizer, num_epochs=10, device='cpu'):\n",
    "    model.to(device)\n",
    "    \n",
    "    # Lists to store loss and accuracy for each epoch\n",
    "    epoch_losses = []\n",
    "    epoch_accuracies = []\n",
    "    schedular = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max= num_epochs, eta_min=0)\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set the model to training mode\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        # Create a tqdm progress bar for the training process\n",
    "        progress_bar = tqdm.tqdm(enumerate(train_loader), total=len(train_loader), desc=f'Epoch {epoch+1}/{num_epochs}')\n",
    "        \n",
    "        # Iterate through the batches of the training dataset\n",
    "        for batch_idx, (inputs, targets) in progress_bar:\n",
    "            \n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Accumulate loss for the epoch and calculate the\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "            total += targets.size(0)\n",
    "            \n",
    "            # Update tqdm progress bar with loss and accuracy\n",
    "            progress_bar.set_postfix(loss=loss.item(), accuracy=correct / total * 100)\n",
    "        \n",
    "        # Calculate average loss and accuracy for this epoch\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_accuracy = correct / total * 100\n",
    "        \n",
    "        # Store the loss and accuracy\n",
    "        epoch_losses.append(epoch_loss)\n",
    "        epoch_accuracies.append(epoch_accuracy)\n",
    "        schedular.step()\n",
    "        # Print statistics for each epoch\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%')\n",
    "    \n",
    "    print('Training completed!')\n",
    "    \n",
    "    # Return the losses and accuracies\n",
    "    return epoch_losses, epoch_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss and accuracy over epochs\n",
    "def plot_loss_and_accuracy(losses, accuracies):\n",
    "    epochs = range(1, len(losses) + 1)\n",
    "    \n",
    "    # Plotting loss\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, losses, label='Loss', color='red')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Loss over Epochs')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Plotting accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, accuracies, label='Accuracy', color='blue')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.title('Accuracy over Epochs')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference function\n",
    "def inference_model_function(model, data_loader, device='cpu'):\n",
    "    model.to(device)  # Move the model to the specified device (CPU or GPU)\n",
    "    model.eval()  # Set the model to evaluation mode (turns off dropout, batch norm, etc.)\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in data_loader: \n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # Forward pass through the model\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # Get the predicted class and accumilate (with the highest score)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            predictions.extend(predicted.cpu().numpy())\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = (correct / total )* 100  # Multiply by 100 to get percentage\n",
    "    return predictions, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_single_image_function(model, image, device='cpu'):\n",
    "    \"\"\"Predict the class of a single image.\"\"\"\n",
    "    # Set the model to evaluation mode\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(image.unsqueeze(0))\n",
    "        _, predicted = torch.max(output, 1)\n",
    "    return predicted.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the Basic Residual Block used in ResNet-18\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        \n",
    "        # First convolutional layer\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        # Second convolutional layer\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        # Shortcut layer\n",
    "        self.shortcut_conv = None\n",
    "        self.shortcut_bn = None\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            # Shortcut layer for matching dimensions if needed\n",
    "            print(f'Shortcut:::: Input Channels: {in_channels}, Output Channels: {out_channels}')\n",
    "            self.shortcut_conv = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False)\n",
    "            self.shortcut_bn = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = x\n",
    "        \n",
    "        # First conv + BN + ReLU\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        # min_value = out.min()\n",
    "        # max_value = out.max()\n",
    "        # max_index = out.argmax()\n",
    "        # print(f'second conv - min: {min_value}, max: {max_value}, max index: {max_index}')\n",
    "        \n",
    "        out = F.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        \n",
    "        # min_value = out.min()\n",
    "        # max_value = out.max()\n",
    "        # max_index = out.argmax()\n",
    "        # print(f'second conv - min: {min_value}, max: {max_value}, max index: {max_index}')\n",
    "        # Apply shortcut if dimensions do not match\n",
    "        if self.shortcut_conv is not None:\n",
    "            shortcut = self.shortcut_conv(x)\n",
    "            shortcut = self.shortcut_bn(shortcut)\n",
    "            # min_value = shortcut.min()\n",
    "            # max_value = shortcut.max()\n",
    "            # max_index = shortcut.argmax()\n",
    "            # print(f'Shortcut:::: min: {min_value}, max: {max_value}, max index: {max_index}')\n",
    "        \n",
    "        out += shortcut\n",
    "        out = F.relu(out)\n",
    "        # min_value = out.min()\n",
    "        # max_value = out.max()\n",
    "        # max_index = out.argmax()\n",
    "        # print(f'min: {min_value}, max: {max_value}, max index: {max_index}')\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the ResNet-18 model\n",
    "class ResNet20(nn.Module):\n",
    "    def __init__(self, channel_values, num_classes=10):\n",
    "        super(ResNet20, self).__init__()\n",
    "        \n",
    "        # Initial convolutional layer\n",
    "        self.conv1 = nn.Conv2d(3, channel_values[0], kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(channel_values[0])\n",
    "        \n",
    "        # Define each residual block with two BasicBlocks each\n",
    "        self.layer1_block1 = BasicBlock(channel_values[0], channel_values[0])\n",
    "        self.layer1_block2 = BasicBlock(channel_values[0], channel_values[0])\n",
    "        self.layer1_block3 = BasicBlock(channel_values[0], channel_values[0])\n",
    "        \n",
    "        self.layer2_block1 = BasicBlock(channel_values[0], channel_values[1], stride=2)\n",
    "        self.layer2_block2 = BasicBlock(channel_values[1], channel_values[1])\n",
    "        self.layer2_block3 = BasicBlock(channel_values[1], channel_values[1])\n",
    "        \n",
    "        self.layer3_block1 = BasicBlock(channel_values[1], channel_values[2], stride=2)\n",
    "        self.layer3_block2 = BasicBlock(channel_values[2], channel_values[2])\n",
    "        self.layer3_block3 = BasicBlock(channel_values[2], channel_values[2])\n",
    "        \n",
    "        # Fully connected layer\n",
    "        # self.avgpool = nn.AvgPool2d(kernel_size=8)\n",
    "        self.avgpool = nn.AvgPool2d(kernel_size=8)\n",
    "        self.fc = nn.Linear(channel_values[2], num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initial conv + batch norm + ReLU + max pooling\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # Layer 1 (64 -> 64 channels, stride=1)\n",
    "        x = self.layer1_block1(x)\n",
    "        x = self.layer1_block2(x)\n",
    "        x = self.layer1_block3(x)\n",
    "        # min_value = x.min()\n",
    "        # max_value = x.max()\n",
    "        # max_index = x.argmax()\n",
    "        # print(f'min: {min_value}, max: {max_value}, max index: {max_index}')\n",
    "        \n",
    "        # Layer 2 (64 -> 128 channels, stride=2)\n",
    "        x = self.layer2_block1(x)\n",
    "        x = self.layer2_block2(x)\n",
    "        x = self.layer2_block3(x)\n",
    "        \n",
    "        # Layer 3 (128 -> 256 channels, stride=2)\n",
    "        x = self.layer3_block1(x)\n",
    "        x = self.layer3_block2(x)\n",
    "        x = self.layer3_block3(x)\n",
    "        \n",
    "        # Global average pooling and fully connected layer\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "# channel_values = [16, 32, 64]\n",
    "# print(channel_values)\n",
    "# num_classes = 10\n",
    "# model = ResNet20(channel_values, num_classes)\n",
    "# # Define the loss function and optimizer\n",
    "# criterion = nn.CrossEntropyLoss()  # Cross entropy loss for classification\n",
    "# optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)  # Adam optimizer\n",
    "# epoch_losses, epoch_accuracies = train_model_function(model, train_loader, criterion, optimizer, num_epochs=no_epochs, device=device)\n",
    "\n",
    "# current_date = datetime.now().strftime('%Y-%m-%d')\n",
    "# save_path = f'models/resnet20_{current_date}.pth'\n",
    "# torch.save(model.state_dict(), save_path)\n",
    "# print(f\"\\nmodel saved at {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shortcut:::: Input Channels: 16, Output Channels: 32\n",
      "Shortcut:::: Input Channels: 32, Output Channels: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_346581/3149330441.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('./../models/resnet20_2025-01-26.pth'), strict=False)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channel_values = [16, 32, 64]\n",
    "num_classes = 10\n",
    "model = ResNet20(channel_values, num_classes).to(device)\n",
    "model.load_state_dict(torch.load('./../models/resnet20_2025-01-26.pth'), strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.manual_seed(0)\n",
    "# redictions, accuracy = inference_model_function(model, test_loader, device=device)\n",
    "# print(f'Inference Accuracy: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1\n",
      "min: 0.0, max: 5.329499244689941, max index: 1673\n",
      "Image 1 - True Label: 3, Predicted Label: 3\n",
      "min: 0.0, max: 5.425549030303955, max index: 1774\n",
      "Image 2 - True Label: 8, Predicted Label: 8\n",
      "min: 0.0, max: 4.0408711433410645, max index: 13787\n",
      "Image 3 - True Label: 8, Predicted Label: 8\n",
      "min: 0.0, max: 4.455061912536621, max index: 1478\n",
      "Image 4 - True Label: 0, Predicted Label: 0\n",
      "min: 0.0, max: 5.262706756591797, max index: 1675\n",
      "Image 5 - True Label: 6, Predicted Label: 6\n",
      "min: 0.0, max: 4.144146919250488, max index: 1641\n",
      "Image 6 - True Label: 6, Predicted Label: 6\n",
      "min: 0.0, max: 5.2371063232421875, max index: 8867\n",
      "Image 7 - True Label: 1, Predicted Label: 1\n",
      "min: 0.0, max: 4.414679050445557, max index: 1447\n",
      "Image 8 - True Label: 6, Predicted Label: 6\n",
      "min: 0.0, max: 4.704330921173096, max index: 1249\n",
      "Image 9 - True Label: 3, Predicted Label: 3\n",
      "min: 0.0, max: 4.349051475524902, max index: 1237\n",
      "Image 10 - True Label: 1, Predicted Label: 1\n",
      "min: 0.0, max: 3.676577568054199, max index: 13891\n",
      "Image 11 - True Label: 0, Predicted Label: 0\n",
      "min: 0.0, max: 5.100053787231445, max index: 5608\n",
      "Image 12 - True Label: 9, Predicted Label: 9\n",
      "min: 0.0, max: 3.845390796661377, max index: 8985\n",
      "Image 13 - True Label: 5, Predicted Label: 5\n",
      "min: 0.0, max: 5.461273193359375, max index: 1326\n",
      "Image 14 - True Label: 7, Predicted Label: 7\n",
      "min: 0.0, max: 5.013214111328125, max index: 10376\n",
      "Image 15 - True Label: 9, Predicted Label: 9\n",
      "min: 0.0, max: 6.871003150939941, max index: 1807\n",
      "Image 16 - True Label: 8, Predicted Label: 8\n",
      "min: 0.0, max: 5.18247127532959, max index: 7198\n",
      "Image 17 - True Label: 5, Predicted Label: 5\n",
      "min: 0.0, max: 6.073422431945801, max index: 1263\n",
      "Image 18 - True Label: 7, Predicted Label: 7\n",
      "min: 0.0, max: 4.892088890075684, max index: 1665\n",
      "Image 19 - True Label: 8, Predicted Label: 8\n",
      "min: 0.0, max: 3.9263648986816406, max index: 1973\n",
      "Image 20 - True Label: 6, Predicted Label: 6\n",
      "min: 0.0, max: 4.4584269523620605, max index: 1643\n",
      "Wrong Prediction for Image 21 - True Label: 7, Predicted Label: 5\n",
      "min: 0.0, max: 5.139430046081543, max index: 1711\n",
      "Image 22 - True Label: 0, Predicted Label: 0\n",
      "min: 0.0, max: 4.39702033996582, max index: 1645\n",
      "Image 23 - True Label: 4, Predicted Label: 4\n",
      "min: 0.0, max: 4.45288610458374, max index: 9000\n",
      "Image 24 - True Label: 9, Predicted Label: 9\n",
      "min: 0.0, max: 6.1468706130981445, max index: 7134\n",
      "Image 25 - True Label: 5, Predicted Label: 5\n"
     ]
    }
   ],
   "source": [
    "# Load 10 images from the MNIST dataset\n",
    "test_loader = DataLoader(test_dataset, batch_size=25, shuffle=False)\n",
    "# Predict and display the result for each image in the batch\n",
    "for batch_idx, (images, targets) in enumerate(test_loader):\n",
    "\tprint(f'Batch {batch_idx + 1}')\n",
    "\tfor idx in range(len(images)):\n",
    "\t\timage = images[idx]\n",
    "\t\ttarget = targets[idx].item()\n",
    "\t\tpredicted_class = predict_single_image_function(model, image, device='cpu')\n",
    "\t\tif(target != predicted_class):\n",
    "\t\t\tprint(f'Wrong Prediction for Image {idx + 1} - True Label: {target}, Predicted Label: {predicted_class}')\n",
    "\t\telse:\n",
    "\t\t\tprint(f'Image {idx + 1} - True Label: {target}, Predicted Label: {predicted_class}')\n",
    "\tbreak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)\n",
    "# true_labels_path = './../../results/resnet20/truelabels.txt'\n",
    "# cnnpredictions_path = './../../results/resnet20/pytorchpredictions.txt'\n",
    "# # Open files for writing true labels and predictions\n",
    "# with open(true_labels_path, 'w') as true_labels_file, open(cnnpredictions_path, 'w') as predictions_file:\n",
    "#     for batch_idx, (images, targets) in enumerate(test_loader):\n",
    "#         for idx in range(len(images)):\n",
    "#             image = images[idx]\n",
    "#             target = targets[idx].item()\n",
    "#             predicted_class = predict_single_image_function(model, image, device='cpu')\n",
    "            \n",
    "#             # Write true label and predicted label to their respective files\n",
    "#             true_labels_file.write(f'{target}\\n')\n",
    "#             predictions_file.write(f'{predicted_class}\\n')\n",
    "            \n",
    "#             # Print result to the console\n",
    "#             if(target != predicted_class):\n",
    "#                 print(f'Wrong Prediction for Image {idx + 1} - True Label: {target}, Predicted Label: {predicted_class}')\n",
    "#             else:\n",
    "#                 print(f'Image {idx + 1} - True Label: {target}, Predicted Label: {predicted_class}')\n",
    "#         break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
